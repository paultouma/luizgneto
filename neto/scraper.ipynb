{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this cell first, it will open a chromedriver\n",
    "#import libraries\n",
    "import selenium \n",
    "from selenium import webdriver\n",
    "import time\n",
    "import pickle\n",
    "import itertools\n",
    "from bs4 import BeautifulSoup\n",
    "import pickle\n",
    "import csv\n",
    "\n",
    "#setup and return driver\n",
    "def setup_driver():\n",
    "    #add header(User-Agent) so website thinks it's an authentic request\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument(\"--disable-infobars\")\n",
    "    chrome_options.add_argument(\"--user-agent=Chrome/74.0.3729.131\")\n",
    "    driver = webdriver.Chrome(\"./chromedriver\", options=chrome_options)\n",
    "    \n",
    "    driver.get(\"https://investovc.com/fundadores\")\n",
    "    return driver\n",
    "\n",
    "#get all of the fund elements\n",
    "def get_funds(driver):\n",
    "    funds_container = driver.find_elements_by_xpath(\"//div[@class='panel-group']\")[0]\n",
    "    funds = funds_container.find_elements_by_xpath(\"//div[contains(@class, 'panel-heading panel-head')]\")\n",
    "    return funds\n",
    "\n",
    "#get the fund title\n",
    "def get_fund_title(ind, fund):\n",
    "    title_elm = fund.find_elements_by_xpath(\"//h3[@class='panel-title']\")[ind]\n",
    "    return title_elm.get_attribute(\"innerHTML\")\n",
    "\n",
    "#get startups for fund\n",
    "def get_startups_for_fund(ind, driver):\n",
    "    desc_elm = driver.find_elements_by_xpath(\"//h4[@class='panel-title']\")[ind]\n",
    "    desc_elm = desc_elm.get_attribute(\"innerHTML\")\n",
    "    desc_elm = [int(s) for s in desc_elm.split() if s.isdigit()][0]\n",
    "    return desc_elm\n",
    "\n",
    "#clean the description\n",
    "def clean_description(description):\n",
    "    description= description.replace(u'\\xa0', u' ')\n",
    "    description = description.replace('Show more>', '')\n",
    "    description =description.replace('Show less>', '')\n",
    "    description = description.replace('...', '')\n",
    "    return description \n",
    "\n",
    "#generic clean text\n",
    "def clean_text(loc):\n",
    "    loc = loc.replace('\\n',\"\")\n",
    "    loc = loc.replace('<p>',\"\")\n",
    "    loc = loc.replace('</p>',\"\")\n",
    "    loc = loc.replace('-',\"\")\n",
    "    return loc\n",
    "\n",
    "def get_startup_info_from_panel(driver):\n",
    "    panel = driver.find_elements_by_xpath(\"//div[@class='sweet-alert sa-investors-modal showSweetAlert visible']\")\n",
    "    \n",
    "    if len (panel) == 0 :\n",
    "        return None\n",
    "    panel_html = panel[0].get_attribute(\"innerHTML\")\n",
    "    soup = BeautifulSoup(panel_html, 'html.parser')\n",
    "    company_name = soup.find_all('h3')[0].text\n",
    "    location = soup.find_all('p')[1].text\n",
    "    description = soup.find('span',{'class':'tagline_style'}).text\n",
    "    img_url = soup.find('img',{'class': 'panel-startup-logo-image'})['src']\n",
    "    website = soup.find_all('p')[3].text\n",
    "    raised = soup.find_all('p')[5].text\n",
    "    founders_elms = soup.find_all('h3')[1:]\n",
    "    founders = list({founder_elm.text.strip() for founder_elm in founders_elms})\n",
    "    \n",
    "    startup_info = {\"name\": company_name.strip(),\n",
    "                    \"location\": \" \".join(location.replace(\"\\n\",\"\").split()).replace(\" -\", \",\"),\n",
    "                    \"description\": description.strip(),\n",
    "                    \"icon_url\": img_url.strip(),\n",
    "                    \"website\": website.strip(),\n",
    "                    \"amount_raised\": raised.strip(),\n",
    "                    \"founders\": founders}\n",
    "\n",
    "    driver.find_elements_by_class_name(\"confirm\")[0].send_keys(u'\\ue007')\n",
    "    time.sleep(1)\n",
    "    return startup_info\n",
    "\n",
    "def read_startups(startups, all_info, driver):\n",
    "    time.sleep(3)\n",
    "    #get all of the startups\n",
    "    startup_count = 0\n",
    "\n",
    "    for fund_count, info in enumerate(all_info):\n",
    "        amount = info[\"fund_amt\"]\n",
    "        startups_for_fund = []\n",
    "        print(\"Fund: \", fund_count+1)\n",
    "\n",
    "        for i in range(amount):\n",
    "            current_startup = startups[startup_count]\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView();\", current_startup)\n",
    "            startup_count +=1\n",
    "\n",
    "            #click and get startup information\n",
    "            current_startup.click()\n",
    "            time.sleep(2)\n",
    "            try:\n",
    "                specific_info = get_startup_info_from_panel(driver)\n",
    "            except Exception as e:\n",
    "                specific_info = None\n",
    "                driver.find_elements_by_class_name(\"confirm\")[0].send_keys(u'\\ue007')\n",
    "                time.sleep(1)\n",
    "            if not specific_info == None:\n",
    "                startups_for_fund.append(specific_info)\n",
    "\n",
    "            print(i + 1, \" of \", amount)\n",
    "\n",
    "        all_info[fund_count][\"startups\"] = startups_for_fund\n",
    "    return all_info\n",
    "\n",
    "def load_page(driver):\n",
    "    all_info = []\n",
    "    funds = get_funds(driver)\n",
    "    funds_len = len(funds)\n",
    "\n",
    "    #go through all of the funds in the current page, and open them\n",
    "    for ind in range(funds_len):\n",
    "\n",
    "        #click to open\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView();\", funds[ind])\n",
    "        fund_title = get_fund_title(ind, funds[ind])\n",
    "        fund_amt = get_startups_for_fund(ind, driver)\n",
    "        funds[ind].click()\n",
    "        time.sleep(2)\n",
    "\n",
    "        all_info.append({\"fund_name\": fund_title, \"fund_amt\":fund_amt})\n",
    "    \n",
    "    #gather location, description, url for each\n",
    "    fund_full_blocks = driver.find_elements_by_xpath(\"//div[@class='panel panel-default panel-startup']\")\n",
    "    for i,fund_full_block in enumerate(fund_full_blocks):\n",
    "        soup = fund_full_block.get_attribute(\"innerHTML\")\n",
    "        soup = BeautifulSoup(soup)\n",
    "        info_blocks = soup.find_all('div',{'class':'tcb-info-block'})\n",
    "        description = \"Not on website\"\n",
    "        location = \"Not on website\"\n",
    "        url = \"Not on website\"\n",
    "        for j, info_block in enumerate(info_blocks):\n",
    "            if \"Startup Description:\" in info_block.text:\n",
    "                description = info_blocks[j + 1].text.replace(\"\\n\",\"\")\n",
    "            elif \"Location\" in info_block.text:\n",
    "                location = \" \".join(info_blocks[j + 1].text.replace(\"\\n\",\"\").split()).replace(\" -\", \",\")\n",
    "            elif \"Web Presence:\" in info_block.text:\n",
    "                url = info_block.findNext('a').get(\"href\")\n",
    "        all_info[i][\"description\"] = description\n",
    "        all_info[i][\"location\"] = location\n",
    "        all_info[i][\"url\"] = url\n",
    "    \n",
    "    #click on all the more buttons\n",
    "    time.sleep(3)\n",
    "    more_buttons = driver.find_elements_by_xpath(\"//div[@class='investor_block investor-more-investments']\")\n",
    "    for more_button in more_buttons:\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView();\", more_button)\n",
    "        more_button.click()\n",
    "        time.sleep(3)\n",
    "    time.sleep(5)\n",
    "    startups = driver.find_elements_by_xpath(\"//div[@class='investor_block  quickinfo quickinfo-startup ']\")\n",
    "    \n",
    "    return read_startups(startups, all_info, driver)\n",
    "\n",
    "#open original page, let it load\n",
    "c_driver = setup_driver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fund:  1\n",
      "1  of  1\n",
      "Fund:  2\n",
      "1  of  1\n",
      "Fund:  3\n",
      "1  of  1\n",
      "Fund:  4\n",
      "1  of  1\n",
      "Fund:  5\n",
      "1  of  1\n",
      "Fund:  6\n",
      "1  of  1\n",
      "Fund:  7\n",
      "1  of  1\n",
      "Fund:  8\n",
      "1  of  1\n",
      "Fund:  9\n",
      "1  of  1\n",
      "Fund:  10\n",
      "1  of  1\n",
      "Fund:  11\n",
      "1  of  1\n",
      "Fund:  12\n",
      "1  of  1\n",
      "Fund:  13\n",
      "1  of  1\n",
      "Fund:  14\n",
      "1  of  1\n",
      "Fund:  15\n",
      "1  of  1\n",
      "Fund:  16\n",
      "1  of  1\n",
      "Fund:  17\n",
      "1  of  1\n",
      "Fund:  18\n",
      "1  of  1\n",
      "Fund:  19\n",
      "1  of  1\n",
      "Fund:  20\n",
      "1  of  1\n",
      "Fund:  21\n",
      "1  of  1\n",
      "Fund:  22\n",
      "1  of  1\n",
      "Fund:  23\n",
      "1  of  1\n",
      "Fund:  24\n",
      "1  of  1\n",
      "Fund:  25\n",
      "1  of  1\n",
      "Fund:  1\n",
      "1  of  1\n",
      "Fund:  2\n",
      "1  of  1\n",
      "Fund:  3\n",
      "1  of  1\n",
      "Fund:  4\n",
      "1  of  1\n",
      "Fund:  5\n",
      "1  of  1\n",
      "Fund:  6\n",
      "1  of  1\n",
      "Fund:  7\n",
      "1  of  1\n",
      "Fund:  8\n",
      "1  of  1\n",
      "Fund:  9\n",
      "1  of  1\n",
      "Fund:  10\n",
      "1  of  1\n",
      "Fund:  11\n",
      "1  of  1\n",
      "Fund:  12\n",
      "1  of  1\n",
      "Fund:  13\n",
      "1  of  1\n",
      "Fund:  14\n",
      "1  of  1\n",
      "Fund:  15\n",
      "1  of  1\n",
      "Fund:  16\n",
      "1  of  1\n",
      "Fund:  17\n",
      "1  of  1\n"
     ]
    }
   ],
   "source": [
    "#get page num programatically\n",
    "if \"page\" in c_driver.current_url:\n",
    "    page_num = c_driver.current_url[c_driver.current_url.index(\"-\") + 1:]\n",
    "else:\n",
    "    page_num = \"1\"\n",
    "\n",
    "############# CAN TOUCH BELOW ######################\n",
    "PAGES_TO_SCRAPE = 2\n",
    "############# CAN TOUCH ABOVE ######################\n",
    "\n",
    "ending = int(page_num) + PAGES_TO_SCRAPE - 1\n",
    "\n",
    "all_info = []\n",
    "#Run this cell after choosing the page you want to scrape, info will be saved in the folders afterwards\n",
    "for i in range(PAGES_TO_SCRAPE):\n",
    "    time.sleep(5)\n",
    "    \n",
    "    #gather information\n",
    "    info_for_page = load_page(c_driver)\n",
    "    all_info.extend(info_for_page)\n",
    "    \n",
    "    if int(page_num) + i < ending:\n",
    "        a_next = c_driver.find_elements_by_xpath(\"//a[@class='page-link next']\")[0]\n",
    "        a_next.click()\n",
    "\n",
    "#make CSV file, compiled results\n",
    "keys = all_info[0].keys()\n",
    "with open(\"csv/\" + page_num + \"-\" + str(ending) + '.csv', 'w') as output_file:\n",
    "    dict_writer = csv.DictWriter(output_file, keys)\n",
    "    dict_writer.writeheader()\n",
    "    dict_writer.writerows(all_info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
